[{"citedPaper": {"paperId": "99a01c9c3815d835c202723bf5d1ad9094ba20e3", "url": "https://www.semanticscholar.org/paper/99a01c9c3815d835c202723bf5d1ad9094ba20e3", "title": "REvil Ransomware", "abstract": "A computer network is a valuable resource in today\u2019s digital world, and it supports businesses in carrying out their operations within an increasingly intricate environment. These networks face significant danger from cyber criminals who execute ransomware attacks among other cyberattacks. In such attacks, vital business data gets encrypted and can, therefore, not be accessed without a decryption key. Ransomware was the most rampant malware threat at the time when 60% of managed service providers were attacked in the first half of 2020. Many victims had no option other than paying the demanded ransom hoping that this would make hackers decrypt their files again. We see once again how crucial it is to have strong protection against cyber threats, as organizations increasingly rely on information technology systems. They cannot afford to lose everything due to a virus or a hacker attack. It is worth mentioning, however, that ransomware has evolved with time into a model known as \u2018Ransomware-as-a-Service\u2019 model (RaaS). Under this new scheme, the developer behind any type of ransomware can license it out to different cybercriminals who will then pay for the right to use these programs with one purpose \u2013 launching their ransomware easily and quickly whenever they decide to. This explains the reason such incidents keep growing exponentially each year since, now everyone can try being a criminal thanks to ready-made software kits available on criminal marketplaces worldwide, such as the dark web, etc.", "year": 2024}}, {"citedPaper": {"paperId": "ac675900f7c6c14c8488e09a2a6e8525bcf9d45a", "url": "https://www.semanticscholar.org/paper/ac675900f7c6c14c8488e09a2a6e8525bcf9d45a", "title": "Generative AI", "abstract": null, "year": 2023}}, {"citedPaper": {"paperId": "af87339f36f9735bae708369256e0ed9734dcc22", "url": "https://www.semanticscholar.org/paper/af87339f36f9735bae708369256e0ed9734dcc22", "title": "Do ChatGPT and Other AI Chatbots Pose a Cybersecurity Risk? - An Exploratory Study", "abstract": "The rise of artificial intelligence (AI) has opened up new frontiers in various fields, including natural language processing. One of the most significant advancements in this area is the development of conversational agents (i.e., chatbots), which are computer programs designed to interact with humans through messaging interfaces. The emergence of large language models, such as ChatGPT, has enabled the creation of highly sophisticated chatbots that can mimic human conversations with impressive accuracy. However, the use of these chatbots also poses significant cyber risks that must be addressed. This research paper seeks to investigate the cyber risks associated with the use of ChatGPT and other similar AI-based chatbots, including potential vulnerabilities that could be exploited by malicious actors. As part of this research, a survey was conducted to explore the cybersecurity risks associated with AI-based chatbots like ChatGPT. Further, the paper also suggests mitigation methods that can be used to mitigate these cyber risks and vulnerabilities.", "year": 2023}}, {"citedPaper": {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "url": "https://www.semanticscholar.org/paper/163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report", "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.", "year": 2023}}, {"citedPaper": {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "url": "https://www.semanticscholar.org/paper/57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models", "abstract": "We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.", "year": 2023}}, {"citedPaper": {"paperId": "ecd0b23e4828fca585a05eff56563852d35858d9", "url": "https://www.semanticscholar.org/paper/ecd0b23e4828fca585a05eff56563852d35858d9", "title": "ChatGPT", "abstract": null, "year": 2023}}, {"citedPaper": {"paperId": "b0a05dafc199f146a25ce8d4f0ec56b886bc8887", "url": "https://www.semanticscholar.org/paper/b0a05dafc199f146a25ce8d4f0ec56b886bc8887", "title": "A Survey on Adversarial Attacks for Malware Analysis", "abstract": "Machine learning-based malware analysis approaches are widely researched and deployed in critical infrastructures for detecting and classifying evasive and growing malware threats. However, minor perturbations or ineffectual byte insertions can easily \u2018fool\u2019 these trained ML classifiers, making them ineffective against these crafted and smart malicious software. This survey aims to provide an encyclopedic overview of adversarial evasion attacks specifically targeting malware detection and classification systems, standing apart from previous surveys by focusing exclusively and comprehensively on this unique application domain. While significant strides have been made in adversarial research in other fields, the specific challenges of adversarial malware remain under-explored due to the intricate nature and constraints of the malware domain. Our survey addresses this gap by analyzing literature on adversarial evasion attacks published between 2013 and 2024, making it one of the first to systematically focus on malware-specific adversarial attacks in a detailed, self-contained manner. The paper will begin by introducing various machine-learning techniques used to generate adversarial malware samples, including the structural nuances of target files, which influence adversarial vulnerabilities. The work presents an in-depth threat model specific to adversarial malware evasion attacks, describing the unique attack surfaces of malware detectors and outlining adversarial goals tailored to the malware domain. We systematically analyze adversarial generation algorithms from broader domains adapted to malware evasion attacks, proposing a taxonomy of adversarial evasion attacks within malware detection based on target domains(Windows, Android and PDF). The survey highlights real-world adversarial evasion attacks on machine learning-based anti-malware engines under each taxonomical heading, demonstrating the evolution and refinement of these attack strategies over time. Our survey outlines current limitations and practical challenges in executing adversarial attacks against malware detectors in real-world environments. We identify open problems and propose future research directions for developing more practical, robust, efficient, and generalized adversarial attacks on ML-based malware classifiers.", "year": 2021}}, {"citedPaper": {"paperId": null, "url": null, "title": "Transformers: State-of-the-Art Natural Language Processing", "abstract": null, "year": 2020}}, {"citedPaper": {"paperId": "d08463bd665589d04619f04dbde84183ffcf2e63", "url": "https://www.semanticscholar.org/paper/d08463bd665589d04619f04dbde84183ffcf2e63", "title": "Towards a Human-like Open-Domain Chatbot", "abstract": "We present Meena, a multi-turn open-domain chatbot trained end-to-end on data mined and filtered from public domain social media conversations. This 2.6B parameter neural network is simply trained to minimize perplexity of the next token. We also propose a human evaluation metric called Sensibleness and Specificity Average (SSA), which captures key elements of a human-like multi-turn conversation. Our experiments show strong correlation between perplexity and SSA. The fact that the best perplexity end-to-end trained Meena scores high on SSA (72% on multi-turn evaluation) suggests that a human-level SSA of 86% is potentially within reach if we can better optimize perplexity. Additionally, the full version of Meena (with a filtering mechanism and tuned decoding) scores 79% SSA, 23% higher in absolute SSA than the existing chatbots we evaluated.", "year": 2020}}, {"citedPaper": {"paperId": "9445423239efb633f5c15791a7abe352199ce678", "url": "https://www.semanticscholar.org/paper/9445423239efb633f5c15791a7abe352199ce678", "title": "General Data Protection Regulation", "abstract": "Presentacio sobre l'Oficina de Proteccio de Dades Personals de la UAB i la politica Open Science. Va formar part de la conferencia \"Les politiques d'Open Data / Open Acces: Implicacions a la recerca\" orientada a investigadors i gestors de projectes europeus que va tenir lloc el 20 de setembre de 2018 a la Universitat Autonoma de Barcelona", "year": 2018}}, {"citedPaper": {"paperId": "13bc4e683075bdd6a3f0155241c276a772d4aa06", "url": "https://www.semanticscholar.org/paper/13bc4e683075bdd6a3f0155241c276a772d4aa06", "title": "Generative adversarial networks", "abstract": "Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.", "year": 2014}}, {"citedPaper": {"paperId": "b2585b3cdcb81db887f756b8f90fd0e04f9ef952", "url": "https://www.semanticscholar.org/paper/b2585b3cdcb81db887f756b8f90fd0e04f9ef952", "title": "Discriminative n-gram language modeling", "abstract": null, "year": 2007}}, {"citedPaper": {"paperId": "c7d6de27864606ed8c19a48c24edf7263213d07b", "url": "https://www.semanticscholar.org/paper/c7d6de27864606ed8c19a48c24edf7263213d07b", "title": "What is it and how does it work?", "abstract": "It must be pointed out that Bain & Spoerel\u2019 in their original paper demonstrated that, under clinical conditions with spontaneously breathing patients, and a fresh gas flow of 7 litres/minute for patients over 50 kg body weight and 5.5 litres/minute for aN patients under 50 kg (including infants), arterial carbon dioxide tensions (PaC02) remained at acceptable levels. These differences in fresh gas flow to body weight ratio may be corelated with the respiratory rate and the relative length of the expiratory pause. Many clinicians have found the Bain system to be satisfactory for spontaneously breathing patients in practice with spontaneously respiring patients provided that this rule is followed-except, perhaps, for patients in excess of 80 kg body weight when slightly higher fresh gas rates are required. THE EDITOR", "year": 1981}}, {"citedPaper": {"paperId": null, "url": null, "title": "4 ChatGPT Cybersecurity Benefits for the Enterprise", "abstract": null, "year": 2023}}, {"citedPaper": {"paperId": null, "url": null, "title": "Security Intelligence", "abstract": null, "year": 2023}}, {"citedPaper": {"paperId": null, "url": null, "title": "What is WannaCry Ransomware? Accessed: May 26, 2023", "abstract": null, "year": 2023}}, {"citedPaper": {"paperId": null, "url": null, "title": "GPT-1 to GPT-4: Each of OpenAI\u2019s GPT models explained and compared", "abstract": null, "year": 2023}}, {"citedPaper": {"paperId": null, "url": null, "title": "How to Build an AI-Powered Chatbot?", "abstract": null, "year": 2023}}, {"citedPaper": {"paperId": null, "url": null, "title": "Chat Spills its Secrets Via Prompt Injection Attack", "abstract": null, "year": 2023}}, {"citedPaper": {"paperId": null, "url": null, "title": "Latest version of ChatGPT Aces Bar Exam with score nearing 90th percentile", "abstract": null, "year": 2023}}, {"citedPaper": {"paperId": "9da775993a4f361edd3b99f652a287ed6ce105fe", "url": "https://www.semanticscholar.org/paper/9da775993a4f361edd3b99f652a287ed6ce105fe", "title": "Weaponized AI for cyber attacks", "abstract": null, "year": 2021}}, {"citedPaper": {"paperId": "10ac0231449e592ca728c9fbe57ba13c2fb03f63", "url": "https://www.semanticscholar.org/paper/10ac0231449e592ca728c9fbe57ba13c2fb03f63", "title": "Meltdown and Spectre", "abstract": null, "year": 2018}}, {"citedPaper": {"paperId": "1114ef6ef315a23755740545ee46c5af0cf1e02c", "url": "https://www.semanticscholar.org/paper/1114ef6ef315a23755740545ee46c5af0cf1e02c", "title": "One Bit Flips, One Cloud Flops: Cross-VM Row Hammer Attacks and Privilege Escalation", "abstract": "Row hammer attacks exploit electrical interactions between neighboring memory cells in high-density dynamic random-access memory (DRAM) to induce memory errors. By rapidly and repeatedly accessing DRAMs with specific patterns, an adversary with limited privilege on the target machine may trigger bit flips in memory regions that he has no permission to access directly. In this paper, we explore row hammer attacks in cross-VM settings, in which a malicious VM exploits bit flips induced by row hammer attacks to crack memory isolation enforced by virtualization. To do so with high fidelity, we develop novel techniques to determine the physical address mapping in DRAMmodules at runtime (to improve the effectiveness of double-sided row hammer attacks), methods to exhaustively hammer a large fraction of physical memory from a guest VM (to collect exploitable vulnerable bits), and innovative approaches to break Xen paravirtualized memory isolation (to access arbitrary physical memory of the shared machine). Our study also suggests that the demonstrated row hammer attacks are applicable in modern public clouds where Xen paravirtualization technology is adopted. This shows that the presented cross-VM row hammer attacks are of practical importance.", "year": 2016}}, {"citedPaper": {"paperId": "3152376af4fc34dc2d360694a218fcff77601326", "url": "https://www.semanticscholar.org/paper/3152376af4fc34dc2d360694a218fcff77601326", "title": "From twitter.", "abstract": "Nurses on Twitter.", "year": 2016}}, {"citedPaper": {"paperId": "6a630ac89d7c0a57eb7bf4cb30dd5946bcf3ccce", "url": "https://www.semanticscholar.org/paper/6a630ac89d7c0a57eb7bf4cb30dd5946bcf3ccce", "title": "google,\u6211,\u8428\u5a1c", "abstract": "IT Status \"Password doesn't match\" error. 4Help is aware that after you change your VT Google password, you will be unable to log on to VT Google Apps services including Mail, Drive, Groups, etc. 4Help is notifying the appropriate people. 12:00 Noon: Engineers have found a backlog on Google password replication. Once the backlog clears you should be able to log on with your changed password that you set earlier. You may be able to log on with your old VT Google password until the system catches up and syncs the new password. Service Degraded Service Degraded [Resolved] Created: Thu, 04/14/2016 11:20am Resolved: Fri, 04/15/2016 1:16pm Duration: 1 day 1 hour 56 min 1734 Views Source URL: https://computing.vt.edu/content/google-0", "year": 2006}}, {"citedPaper": {"paperId": null, "url": null, "title": "deepchecks", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "GPT-4. Accessed", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "the B.E. degree in electronics and communication engineering from the Institute of Engineering, Tribhuvan University, Nepal", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "GenerativeAI\u2014WhatisitandHowDoesitWork?", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "GreyDGL/PentestGPT", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "A History of Generative AI: From GAN to GPT-4", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Despite Being Programmed Not To", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "text=ChatGPT%20could%20support%20overworked%20security", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "www.leewayhertz.com/ai-chatbots/", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "What is ChatGPT? ChatGPT Security Risks", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Darkreading", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "twitter.com/mazen160/status/1598351725756301313", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Chatting Our Way Into Creating a Polymorphic Malware", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Models - OpenAI API", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "NordVPN", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Mimicast", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "OpenAI", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "IEEE Global Initiative Aims to Advance Ethical Design of AI and Autonomous Systems", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "How to jailbreak ChatGPT: Get it to really do what you want", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Ethical Implications Of ChatGPT: The Good, The Bad, The Ugly", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Understanding the Risks of Prompt Injection Attacks on ChatGPT and Other Language Models", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Playbook of the Week: Using ChatGPT in Cortex XSOAR", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "A GPT-Empowered Penetration Testing Tool", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Usage Policies", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Prompt Injection Attack on GPT-4", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "How to Enable ChatGPT Developer Mode: 5 Steps (with Pictures)", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Here\u2019s how anyone can Jailbreak ChatGPT with these top 4 methods", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Using ChatGPT to Improve Your Cybersecurity Posture", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "ZombieLoad Attack. https: //zombieloadattack.com/, 2023. Online; accessed 26", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "Number of ChatGPT Users", "abstract": null, "year": null}}, {"citedPaper": {"paperId": null, "url": null, "title": "From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy", "abstract": null, "year": null}}]